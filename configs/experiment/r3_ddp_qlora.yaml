base_model: meta-llama/Llama-2-7b-hf
run_name: r3_ddp_qlora
output_dir: runs/r3_ddp_qlora

paths:
  data_config: configs/experiment/data_dolly.yaml
  history_csv: runs/r3_ddp_qlora/logs/history.csv

quantization:
  qlora_4bit: true
  nf4: true
  double_quant: true

peft:
  r: 16
  alpha: 16
  dropout: 0.05
  target_modules: [q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj]  # attn+MLP

train:
  epochs: 3
  per_device_batch_size: 1
  grad_accum_steps: 8
  lr: 2.0e-4
  weight_decay: 0.0
  lr_schedule: cosine
  warmup_steps: 50
  bf16: true        
  gradient_checkpointing: true
  logging_steps: 25
  max_seq_len: 2048
  eval_strategy: epoch
  save_strategy: epoch
  save_total_limit: 3
  load_best_model_at_end: true
  metric_for_best_model: eval_loss
  greater_is_better: false
