base_model: meta-llama/Llama-2-7b-hf
run_name: r1_attn_only
output_dir: runs/r1_attn_only/checkpoints
seed: 42

quantization:
  qlora_4bit: true
  nf4: true
  double_quant: true

peft:
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules: [q_proj, k_proj, v_proj, o_proj]

train:
  epochs: 3
  max_seq_len: 2048
  lr: 2.0e-4
  weight_decay: 0.0
  warmup_steps: 200
  lr_schedule: cosine
  per_device_batch_size: 1
  grad_accum_steps: 8
  gradient_checkpointing: true
  logging_steps: 25
  eval_strategy: epoch
  save_strategy: epoch
  load_best_model_at_end: true
  metric_for_best_model: eval_loss
  greater_is_better: false
  bf16: true

paths:
  data_config: configs/experiment/data_dolly.yaml
  history_csv: runs/r1_attn_only/logs/history.csv
